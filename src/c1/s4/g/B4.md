
Consider the following three algorithms:
Algorithm 1 solves problems of size N by recursively dividing them into 2 sub-problems of size N/2 and combining the results in time c (where c is some constant).
Algorithm 2 solves problems of size N by solving one sub-problem of size N/2 and peforming some processing taking some constant time c.
Algorithm 3 solves problems of size N by solving two sub-problems of size N/2 and performing a linear amount (i.e., cN where c is some constant) of extra work.
(a) For each algorithm, write down a recurrence relation showing how T(N), the running time on an instance of size N, depends on the running time of a smaller instance.
(b) For each recurrence relation, what is the running time for each T(N) (use tilde notation)?


1) T(N)=T(N/2)+T(N/2)+c          ~N
2) T(N)=T(N/2)+c                 ~logN
3) T(N)=T(N/2)+T(N/2)+cN         ~N*logN

